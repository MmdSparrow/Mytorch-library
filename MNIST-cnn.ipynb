{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"If it does not work use code below while running this notebook in this dir.\"\n",
    "# import sys\n",
    "# import os\n",
    "# sys.path.append(os.path.abspath(os.getcwd()))\n",
    "\n",
    "from mytorch import Tensor, Model\n",
    "from mytorch import activation as active_func\n",
    "from mytorch import loss as loss_func\n",
    "from mytorch import optimizer as optim \n",
    "from mytorch import layer as nn\n",
    "from mytorch.util import DataLoader\n",
    "\n",
    "from mytorch.util import flatten\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train...\n",
      "loading test...\n",
      "processing...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'you can see how data is loaded'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "load data set with given data loader.\n",
    "you have 10000 train data, 1000 for each number, remember to shuffle training data.\n",
    "you have 1000 test data, 100 for each number.\n",
    "\n",
    "loaded data is a list of (img, label)\n",
    "type of img is Tensor.\n",
    "\n",
    "TODO: you have to get this list and create batches for training.\n",
    "you can also apply this changes later in the Training part for convenience.\n",
    "\"\"\"\n",
    "data_loader = DataLoader(train_addr='MNIST_light/MNIST/train', test_addr='MNIST_light/MNIST/test')\n",
    "data_loader.load(train_batch_size=128, test_batch_size=32, do_normalize=True)\n",
    "\"you can see how data is loaded\"\n",
    "# print(data_loader.getTrain()[0][0].shape)\n",
    "# print(data_loader.getTrain()[0][1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Create your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d1:  conv 2d - total params: 25 - kernel: (5, 5), stride: (1, 1), padding: (0, 0)\n",
      "conv2d2:  conv 2d - total params: 25 - kernel: (5, 5), stride: (1, 1), padding: (0, 0)\n",
      "mp:  max pool 2d - kernel: (2, 2), stride: (2, 2), padding: (0, 0)\n",
      "fc1:  linear - total param: 16000 - in: 160, out: 100\n",
      "fc2:  linear - total param: 1000 - in: 100, out: 10\n"
     ]
    }
   ],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        \"TODO: define your layers. order is important\" \n",
    "        self.conv2d1= nn.Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
    "        self.conv2d2= nn.Conv2d(10, 10, kernel_size=(5, 5), stride=(1, 1))\n",
    "        self.mp = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.fc1 = nn.Linear(4*4*10,100, need_bias=False)\n",
    "        self.fc2 = nn.Linear(100,10, need_bias=False)\n",
    "        self.relu = active_func.relu\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"TODO: define forward pass\"\n",
    "        x = self.conv2d1(x)\n",
    "        x = self.relu(x) #24x24x10\n",
    "        x = self.mp(x) #12x12x10\n",
    "        x = self.conv2d2(x)\n",
    "        x = self.relu(x) #8x8x10\n",
    "        x = self.mp(x) #4x4x10    \n",
    "        # x = x.view(-1, 4*4*10) #flattening\n",
    "        x = flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = MyModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"TODO: choose a proper loss function\"\n",
    "criterion = loss_func.CategoricalCrossEntropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose an Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"TODO: choose a proper optimizer\"\n",
    "optimizer = optim.SGD(model.parameters(), learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just use it for argmax\n",
    "import numpy as np\n",
    "\n",
    "def train_one_epoch(model: Model, data_loader, optimizer: optim, criterion, length):\n",
    "  acc = 0\n",
    "\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  for batch in data_loader.getTrain():\n",
    "      x_train_dev = batch[0]\n",
    "      y_train_dev = batch[1]\n",
    "\n",
    "      y_pred_dev = model(x_train_dev)\n",
    "\n",
    "      loss = criterion(y_pred_dev, y_train_dev)\n",
    "\n",
    "      loss.backward()\n",
    "\n",
    "      optimizer.step()\n",
    "\n",
    "      yp= np.argmax(y_pred_dev.data, axis=1)\n",
    "      acc += np.sum(yp == y_train_dev.data)\n",
    "\n",
    "  return acc/length\n",
    "\n",
    "\n",
    "\n",
    "def caluculate_acc(data_loader, model, length):\n",
    "  acc = 0\n",
    "  for batch in data_loader.getTest():\n",
    "    x_test_dev = batch[0]\n",
    "    y_test_dev = batch[1]\n",
    "    # show_batch(x_test_dev, y_test_dev)\n",
    "    yp = model(x_test_dev)\n",
    "    \n",
    "    yp= np.argmax(yp.data, axis=1)\n",
    "    acc += np.sum(yp == y_test_dev.data)\n",
    "  return acc / length\n",
    "\n",
    "\n",
    "def show_batch(X_train, y_train):\n",
    "  plt.figure(figsize=(10,10))\n",
    "  for i in range(64):\n",
    "      plt.subplot(8,8,i+1)\n",
    "      plt.xticks([])\n",
    "      plt.yticks([])\n",
    "      plt.grid(False)\n",
    "      plt.imshow(X_train[i].data, cmap=plt.cm.binary)\n",
    "      plt.xlabel(y_train[i].data)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [02:56<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "relu() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTODO: train over your defined batches and save train accuracy for each epoch.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# train_acc.append(train_one_epoch(model, data_loader, optimizer, criterion, 10000)[1].item())\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m train_acc\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_train_acc \u001b[38;5;241m<\u001b[39m train_acc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m     16\u001b[0m     best_train_acc \u001b[38;5;241m=\u001b[39m train_acc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn[13], line 13\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, data_loader, optimizer, criterion, length)\u001b[0m\n\u001b[1;32m     10\u001b[0m x_train_dev \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     11\u001b[0m y_train_dev \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 13\u001b[0m y_pred_dev \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_dev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_pred_dev, y_train_dev)\n\u001b[1;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/mnt/c61cae30-2704-4fc9-aebc-309eed0d378c/PR2/PR2/mytorch/model.py:11\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, inp: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 22\u001b[0m, in \u001b[0;36mMyModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m x \u001b[38;5;241m=\u001b[39m flatten(x)\n\u001b[1;32m     21\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x)\n\u001b[0;32m---> 22\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mTypeError\u001b[0m: relu() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "\"TODO: define number of epoch and train batches of data on your model. also test each epoch.\"\n",
    "EPOCH = 10\n",
    "\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "best_train_acc = 0.0\n",
    "best_test_acc = 0.0\n",
    "\n",
    "for i in tqdm(range(EPOCH)):\n",
    "\n",
    "    \"TODO: train over your defined batches and save train accuracy for each epoch.\"\n",
    "    # train_acc.append(train_one_epoch(model, data_loader, optimizer, criterion, 10000)[1].item())\n",
    "    train_acc.append(train_one_epoch(model, data_loader, optimizer, criterion, 10000))\n",
    "    \n",
    "    if best_train_acc < train_acc[-1]:\n",
    "        best_train_acc = train_acc[-1]\n",
    "\n",
    "    \"TODO: test your model after each training and save test accuracy for each epoch.\"\n",
    "\n",
    "    # test_acc.append(caluculate_acc(data_loader, model, 1000).item())\n",
    "    test_acc.append(caluculate_acc(data_loader, model, 1000))\n",
    "\n",
    "\n",
    "    if best_test_acc < test_acc[-1]:\n",
    "        best_test_acc = test_acc[-1]\n",
    "\n",
    "    if train_acc[-1] > 0.99 and test_acc[-1] > 0.99:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc, label='train accuracy')\n",
    "plt.plot(test_acc, label = 'test accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nOn train - best accuracy: {:.2f}, final accuracy: {:.2f}\".format(best_train_acc, train_acc[-1]))\n",
    "print(\"On test - best accuracy: {:.2f}, final accuracy: {:.2f}\".format(best_test_acc, test_acc[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
