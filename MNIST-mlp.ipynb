{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"If it does not work use code below while running this notebook in this dir.\"\n",
    "# import sys\n",
    "# import os\n",
    "# sys.path.append(os.path.abspath(os.getcwd()))\n",
    "\n",
    "from mytorch import Tensor, Model\n",
    "from mytorch import activation as active_func\n",
    "from mytorch import loss as loss_func\n",
    "from mytorch import optimizer as optim \n",
    "from mytorch import layer as nn\n",
    "from mytorch.util import DataLoader\n",
    "\n",
    "from mytorch.util import flatten\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train...\n",
      "loading test...\n",
      "processing...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'you can see how data is loaded'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "load data set with given data loader.\n",
    "you have 10000 train data, 1000 for each number, remember to shuffle training data.\n",
    "you have 1000 test data, 100 for each number.\n",
    "\n",
    "loaded data is a list of (img, label)\n",
    "type of img is Tensor.\n",
    "\n",
    "TODO: you have to get this list and create batches for training.\n",
    "you can also apply this changes later in the Training part for convenience.\n",
    "\"\"\"\n",
    "data_loader = DataLoader(train_addr='MNIST_light/MNIST/train', test_addr='MNIST_light/MNIST/test')\n",
    "data_loader.load(train_batch_size=64, test_batch_size=64)\n",
    "\"you can see how data is loaded\"\n",
    "# print(data_loader.getTrain()[0][0].shape)\n",
    "# print(data_loader.getTrain()[0][1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Create your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1:  linear - total param: 200704 - in: 784, out: 256\n",
      "fc2:  linear - total param: 32768 - in: 256, out: 128\n",
      "fc3:  linear - total param: 8192 - in: 128, out: 64\n",
      "fc4:  linear - total param: 640 - in: 64, out: 10\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \"TODO: define your layers. order is important\" \n",
    "        self.fc1 = nn.Linear(28 * 28, 256)\n",
    "        self.relu = active_func.relu\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        self.softmax = active_func.softmax\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"TODO: define forward pass\"\n",
    "        x = flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.softmax(self.fc4(x))\n",
    "        return x\n",
    "\n",
    "model = MyModel()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"TODO: choose a proper loss function\"\n",
    "\n",
    "criterion = loss_func.CategoricalCrossEntropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose an Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"TODO: choose a proper optimizer\"\n",
    "optimizer = optim.SGD(model.parameters(), learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just use it for argmax\n",
    "import numpy as np\n",
    "\n",
    "def train_one_epoch(model: Model, data_loader, optimizer: optim, criterion, length):\n",
    "  acc = 0\n",
    "  for batch in data_loader.getTrain():\n",
    "      x_train_dev = batch[0]\n",
    "      y_train_dev = batch[1]\n",
    "\n",
    "      y_pred_dev = model(x_train_dev)\n",
    "\n",
    "      loss = criterion(y_pred_dev, y_train_dev)\n",
    "\n",
    "      loss.backward()\n",
    "\n",
    "      optimizer.step()\n",
    "\n",
    "      yp= np.argmax(y_pred_dev.data, axis=1)\n",
    "      acc += np.sum(yp == y_train_dev.data)\n",
    "\n",
    "  return loss.data, acc/length\n",
    "\n",
    "\n",
    "\n",
    "def caluculate_acc(data_loader, model, length):\n",
    "  acc = 0\n",
    "  for batch in data_loader.getTest():\n",
    "    x_test_dev = batch[0]\n",
    "    y_test_dev = batch[1]\n",
    "    yp = model(x_test_dev)\n",
    "\n",
    "    yp= np.argmax(y_test_dev.data, axis=1)\n",
    "    acc += np.sum(yp == y_test_dev.data)\n",
    "  return acc / length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [ 7.14996927e+01 -2.27215756e+01 -2.09676304e+02 -1.13274043e+02\n",
      " -1.44832515e+02  1.30782977e+01  7.03504052e+01  1.23276134e+01\n",
      "  1.29744721e+02  2.91267829e+01 -1.79743489e+00  6.51854032e+01\n",
      " -2.00854714e+01 -1.24183725e+02 -8.14958921e+01  1.18776262e+02\n",
      "  1.29466088e+02 -1.35864046e+02  3.68693578e+01  1.80371389e+02\n",
      "  3.46773201e+01 -1.05760406e+02 -1.23053620e+02  1.94003154e+01\n",
      " -1.96859741e+02 -4.04898355e+01 -1.02094698e+02  3.71761183e+01\n",
      "  5.51158556e+00  1.35906693e+02 -1.99723534e+02 -1.03805816e+02\n",
      "  1.29952246e+02  2.02444672e+02 -1.28054186e+02  3.23738186e+01\n",
      "  2.25988894e+01 -2.70646749e+00 -6.18850327e+01 -8.15232398e+00\n",
      "  1.37524291e+02 -1.08798246e+01  3.36292769e+01  5.63985200e+01\n",
      "  5.95692712e+01 -7.13068718e+00  9.06896255e+00 -1.32974020e+02\n",
      "  1.32054801e+01  3.25994900e+01  7.72716361e+01 -2.88075263e+01\n",
      " -9.77915172e-01 -7.36225894e+00 -2.98525831e+01 -1.29278503e+02\n",
      "  1.48215236e+01 -9.78257445e+01  1.91925242e+02 -2.49764929e+01\n",
      " -7.85071263e+01  1.34088267e+02  1.38544490e+02  1.37529726e+02\n",
      " -8.49362923e+01 -1.24385129e+02  2.35447149e+01 -3.25202113e+01\n",
      " -1.49582898e+01  7.54285139e+01  7.67433806e+01 -2.16137009e+02\n",
      "  2.49060782e+01  5.21229222e+01 -9.27025826e+01  1.46248544e+02\n",
      "  1.03683872e+02 -7.04509175e+01  1.32388326e+02  4.91874497e+01\n",
      "  2.74771060e+01 -6.00339966e+01 -1.26500038e+02 -9.84257433e+01\n",
      " -9.40422472e+01 -1.11510619e+01  6.42928315e+01 -6.47841744e+01\n",
      " -1.29038706e+02  6.01039712e+01 -5.95960096e+01 -4.57153725e+01\n",
      " -2.01825360e+01 -1.83073112e+02 -5.00821534e+01 -3.37788391e+01\n",
      "  2.96857011e+01  6.20905457e+01  2.07353419e+01 -1.16408091e+01\n",
      "  4.10143072e+01 -1.42143159e+01 -1.25471929e+02 -2.40745636e+01\n",
      " -2.25897992e+01 -5.67375839e+01  9.05192567e+01 -1.44207661e+01\n",
      " -1.80891802e+02 -1.01440760e+02  5.02006091e+01 -6.89514945e+01\n",
      " -6.29411248e+01  1.03990949e+02 -5.79762363e+00  1.34050437e+02\n",
      "  1.85923175e+02  8.55137026e+01 -6.26820244e+01  1.35403606e+02\n",
      "  1.19761875e+01  1.44368268e+01  9.55243551e+01 -1.68370828e+02\n",
      " -2.67985580e+01 -7.23249802e+00 -1.60681587e+02  5.79016077e+01\n",
      " -2.83623366e+01 -1.17441266e+01  3.78807937e+01  1.53538455e+01\n",
      " -8.89927569e+01  3.50868512e+01 -7.52688731e+01  5.21356493e+01\n",
      "  8.00714939e+01 -3.78609878e+01 -8.31863555e+01  5.60571031e+01\n",
      " -2.21858522e+01 -6.31679348e+01 -4.53351467e+01  3.15250023e+00\n",
      " -1.04437624e+01 -4.78105126e+01 -2.97020546e+00 -1.64557206e+01\n",
      " -5.07935932e+00 -5.04925659e+01 -1.65993822e+02  9.20755495e+01\n",
      "  5.06055329e+01 -6.10486820e+01  1.01519118e-01 -6.79488493e+01\n",
      "  1.28589193e+01  4.90900398e+01 -1.11076465e+02 -1.16968085e+02\n",
      " -1.20739192e+02 -1.23921885e+02  2.53762733e+02 -4.01783343e+01\n",
      "  3.95478930e+01  1.39443235e+02 -4.21463500e+01 -1.11117046e+02\n",
      " -8.49240050e+01  2.79633958e+01 -2.56778843e+01  4.79197660e+01\n",
      "  1.12189232e+02  4.87377934e+01  1.88014563e+01 -1.58291981e+02\n",
      "  8.15047902e+01 -7.98278072e+00 -9.07186088e+01 -1.64483443e+02\n",
      "  1.35593442e+02  5.45900669e+01 -2.25562849e+01  9.91209527e+01\n",
      " -6.95022899e+00 -5.05285908e+01  2.73887131e+01 -3.65454245e+01\n",
      "  9.02649719e-01 -1.75085701e+01 -7.28145663e+01 -1.81538518e+01\n",
      " -1.17315311e+02  1.71118161e+01  9.81648969e+01 -1.13675172e+02\n",
      " -3.65759395e+01  7.30476981e+01  1.93422124e+02  8.23973276e+00\n",
      " -2.30023543e+01  3.89171070e+01 -2.02130807e+02  1.57683996e+02\n",
      " -1.59809933e+01 -1.33733444e+02  2.86575232e+01  9.50645955e+01\n",
      "  1.38679890e+02 -3.96035419e+00  4.90388200e+01  4.85180287e+01\n",
      " -5.09195313e+01 -7.85434033e+01 -6.80849110e+01  5.52158890e+01\n",
      " -2.69965690e+00 -1.94645783e+01 -7.56424390e+01 -6.21781090e+01\n",
      "  1.48088211e+02  2.10699987e+01  9.28898601e+01 -1.39386590e+02\n",
      " -1.47110531e+02 -8.62927527e+01  6.53077065e+01  9.75330254e+01\n",
      "  4.02542548e+01  3.34142433e+01  7.27213989e+01  1.75357249e+02\n",
      " -2.57643434e+01  1.32866451e+01 -2.67692794e+00 -6.70982201e+01\n",
      "  6.36103049e+01 -4.87266119e+00 -6.34485267e+01  1.37488206e+02\n",
      "  9.41641156e+01  4.37204410e+01 -1.59305557e+00 -5.06425984e+01\n",
      " -4.69187800e+01 -3.73348058e+01  2.18803199e+02  1.11674824e+01\n",
      " -5.62714365e+01 -1.41815099e+02 -8.86162748e+01 -1.02910947e+02\n",
      "  3.49406177e+01  1.12177309e+02 -1.53823612e+01  2.74415880e+01]\n",
      "result: [ 2.50280699e+01 -5.94956926e+00 -4.92291463e+01 -3.71353797e+01\n",
      " -5.20584518e+01 -8.07180698e+01 -9.59923260e+01  1.18676384e+02\n",
      " -2.24453337e+01 -4.18976732e+01  2.17272626e+01  9.11085552e+01\n",
      "  6.47560601e+01 -4.61859689e+00  1.59397718e+02 -1.29460330e+01\n",
      " -2.70683228e+01  1.18364433e+02  3.82752056e+01 -2.88887965e+01\n",
      " -7.84134159e+00 -1.89109344e+01  9.29010443e+01  6.57201012e+01\n",
      "  2.57917888e+01 -6.54759209e+00 -9.80528011e+01 -1.17996906e+01\n",
      " -3.09715436e+01 -7.71999504e+01  1.91938790e+01 -5.87672942e+01\n",
      " -1.35211693e+01  6.19428645e+00  4.49609294e+01  1.10224856e+01\n",
      "  2.39459463e+00  6.57056984e+00  8.33055352e+01  1.33781750e+01\n",
      "  1.61157974e+01  4.52179603e+01  6.57248046e+01  8.30453808e+01\n",
      " -6.92662972e+01 -1.65511609e+01  2.75969725e+01 -9.00429885e+00\n",
      "  9.67689418e+00  2.58983000e+01 -3.68502614e+00  7.46853363e+01\n",
      "  1.30072822e+02 -5.09740245e+00 -4.04281327e+01 -2.78070474e+01\n",
      "  6.83588459e+00  2.34799620e+01  1.61502976e+01 -6.97958928e+01\n",
      " -1.41335432e-01  2.67728920e+01  9.01177374e+01 -9.06650962e+00\n",
      " -7.62107103e+01  2.06387486e+00  7.70133426e+01  5.93790106e+00\n",
      "  5.16784499e-01  7.07696781e+00  5.27170671e+01 -1.12532265e+02\n",
      "  8.12882788e+01 -1.15782733e+02  1.12409174e+02 -2.69432787e+01\n",
      "  1.91284870e+01  6.17192242e+01  6.58080999e+00 -5.01998743e+01\n",
      "  8.80044668e-01  1.28399286e+02 -4.53379871e+01 -7.91425018e+01\n",
      " -2.45365274e+01  3.47113755e+01 -5.97650465e+01 -2.02470241e+01\n",
      " -8.20345506e+00 -4.29392053e+01 -2.66199923e+00  6.42189981e+01\n",
      "  9.24654069e+01  7.33305421e+01 -8.48296987e+00  6.72146203e+01\n",
      "  4.95368104e+01  7.36263875e+01 -5.82693646e+01  6.71464752e+00\n",
      "  3.25605396e+01  8.77398434e+01 -3.64978423e+01 -2.37678544e+01\n",
      " -4.16393130e+01 -4.45332210e+01 -1.62656445e+01 -6.79529243e+01\n",
      " -1.05031468e+02  4.13802821e+00  3.55566307e+00 -1.03565047e+02\n",
      " -8.58942732e+00  7.99970458e+01 -6.94775081e+01  2.19753051e+01\n",
      " -6.54498848e+01  3.11575850e+01  8.25237459e+01  1.84584170e+01\n",
      " -1.54371953e+01  1.58659704e+01  4.17821231e-01 -6.90086502e+01\n",
      " -8.38981685e+01 -9.69071454e+01  6.47674679e+01  1.72997374e+02]\n",
      "result: [ -34.90619817   62.54893355   -7.27384833   42.99697937   23.60086346\n",
      "   10.04510533   46.6726156   -53.24653673   25.71911346   -9.78786289\n",
      "   10.0755897   -30.13673229    1.42775734  -22.55107919  -99.94119703\n",
      "  -34.02148865  -42.87141397   33.99549411   56.06524946  -50.77500243\n",
      "  -45.53997042   29.30447059  -69.25737468   -9.42699112  -23.90243399\n",
      "  -61.31265132   56.50932539   32.14685794   -9.27929787   48.61182968\n",
      "   42.1791706   100.15249758  -28.45751882   73.75289889   91.36222186\n",
      "  -18.27043675    2.25798242  -17.45862318   53.46294535  129.00668551\n",
      "   40.22072952   69.86539138  -30.13654419    8.95399173 -121.55243193\n",
      "  -13.51600332  -54.57563964  -33.98802746    1.33326335  -49.60614719\n",
      "   -6.96540178   60.8009048    -1.14375409    3.21415993   54.85562342\n",
      "  -21.0920675   -26.10339733  112.55833729    2.44259367   -9.00247492\n",
      "  -37.98982362  -15.97322673  -54.92979708   18.45812988]\n",
      "result: [ 49.85649431 -16.43219836 -23.79148286 -72.77047833  18.27505297\n",
      "  -3.05445876 -62.89719957 -44.82149943  33.60513783  64.89253339]\n",
      "Tensor(2146.476177820414, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "\"TODO: define number of epoch and train batches of data on your model. also test each epoch.\"\n",
    "EPOCH = 13\n",
    "\n",
    "for i in range(EPOCH):\n",
    "\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    best_train_acc = 0.0\n",
    "    best_test_acc = 0.0\n",
    "\n",
    "    \"TODO: train over your defined batches and save train accuracy for each epoch.\"\n",
    "    # train_acc.append(train_one_epoch(model, data_loader, optimizer, criterion, 1000)[1].item())\n",
    "    train_acc.append(train_one_epoch(model, data_loader, optimizer, criterion, 1000)[1])\n",
    "    \n",
    "    if best_train_acc < best_train_acc[-1]:\n",
    "        best_train_acc = train_acc[-1]\n",
    "\n",
    "    \"TODO: test your model after each training and save test accuracy for each epoch.\"\n",
    "\n",
    "    # test_acc.append(caluculate_acc(data_loader, model, 1000).item())\n",
    "    test_acc.append(caluculate_acc(data_loader, model, 1000))\n",
    "\n",
    "\n",
    "    if best_test_acc < test_acc[-1]:\n",
    "        best_test_acc = test_acc[-1]\n",
    "\n",
    "    if train_acc[-1] > 0.99 and test_acc[-1] > 0.99:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc, label='train accuracy')\n",
    "plt.plot(test_acc, label = 'test accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nOn train - best accuracy: {:.2f}, final accuracy: {:.2f}\".format(best_train_acc, train_acc[-1]))\n",
    "print(\"On test - best accuracy: {:.2f}, final accuracy: {:.2f}\".format(best_test_acc, test_acc[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
